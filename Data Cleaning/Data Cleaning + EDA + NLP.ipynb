{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f723f1be",
   "metadata": {},
   "source": [
    "## STAT628 Module 3 Yelp Data \n",
    "### Brian Tsai \n",
    "#### mtsai36@wisc.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7a864",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from scipy import stats as st \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as py\n",
    "import seaborn as sns \n",
    "#from langdetect import detect_langs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56516750",
   "metadata": {},
   "source": [
    "### Reading Business json data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad4194b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('C:/Users/tsai_/Downloads/yelp_dataset/yelp_dataset/business.json', encoding = 'utf8') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Mexican restaurants \n",
    "mex = [] \n",
    "for i in range(len(data)): \n",
    "    if data[i]['categories'] != None: \n",
    "        if 'Mex' in data[i]['categories']:\n",
    "            mex.append(data[i])\n",
    "\n",
    "# Mexican restuarants that are open            \n",
    "mex_open = []\n",
    "for i in mex: \n",
    "    if i['is_open'] == 1: \n",
    "        mex_open.append(i)\n",
    "\n",
    "\n",
    "# Business id for open Mexican restuarants         \n",
    "mex_id = []\n",
    "for i in mex_open: \n",
    "    mex_id.append(i['business_id'])\n",
    "\n",
    "# Tacobell restaurants with >= 10 reviews  \n",
    "tacobell = [] \n",
    "tacobell_id = [] \n",
    "for i in mex_open: \n",
    "    if 'Taco Bell' in i['name'] and i['review_count'] >=10: \n",
    "        tacobell.append(i)\n",
    "        tacobell_id.append(i['business_id'])\n",
    "\n",
    "    \n",
    "# Chipotle restaurants with >= 10 reviews \n",
    "chipotle = [] \n",
    "chipotle_id = [] \n",
    "for i in mex_open:\n",
    "    if 'Chipotle Mex' in i['name'] and i['review_count'] >= 10:\n",
    "        chipotle.append(i) \n",
    "        chipotle_id.append(i['business_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d7ea9b",
   "metadata": {},
   "source": [
    "## User json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = []\n",
    "with open('C:/Users/tsai_/Downloads/yelp_dataset/yelp_dataset/user.json', encoding = 'utf8') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        user.append(json.loads(line))\n",
    "df = pd.DataFrame(user)\n",
    "print(len(user))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b7e74",
   "metadata": {},
   "source": [
    "## Tips json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a481c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tacobell_tips = []\n",
    "chipotle_tips = []\n",
    "with open('C:/Users/tsai_/Downloads/yelp_dataset/yelp_dataset/tip.json', encoding = 'utf8') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        x = json.loads(line)\n",
    "        if x['business_id'] in tacobell_id: \n",
    "            tacobell_tips.append(x)\n",
    "        if x['business_id'] in chipotle_id: \n",
    "            chipotle_tips.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1f3e9",
   "metadata": {},
   "source": [
    "## Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73584f16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k9vlSSUStwY2DcjM8Rinnw</td>\n",
       "      <td>7C8RwnXqNhj6mYxowI53sA</td>\n",
       "      <td>Of6xu3pY3eHe2yhiyz2dvg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Literally not a thing, anything at all,  in my...</td>\n",
       "      <td>2017-05-13 05:57:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AtNXA1mJ8BJR1OK7sM68Ug</td>\n",
       "      <td>2Y01picIp0O3uvo45l_jMQ</td>\n",
       "      <td>xyLIKm-pXy-zc29weExTZQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I've lived in the area for 5 years now. This t...</td>\n",
       "      <td>2015-08-19 16:30:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HTvz23J8kC-B9ZaJ_Y9v0Q</td>\n",
       "      <td>D6dvJfPX3Pbcn5JQJZx2xA</td>\n",
       "      <td>Of6xu3pY3eHe2yhiyz2dvg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>This is probably the worst Taco Bell I've ever...</td>\n",
       "      <td>2016-03-07 02:48:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O2KoZYlcLv2QYR5C1WzQiQ</td>\n",
       "      <td>84H-Yk7MaqhCAGdk7UDjuA</td>\n",
       "      <td>8yLc33AAXB9-xn7OG4Firw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Saturday evening, 10:30pm, closed. No explanat...</td>\n",
       "      <td>2018-07-08 02:30:44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>706rWMW5g-IpRT1bGD85GQ</td>\n",
       "      <td>1ENBskBHIvWPaiF-wcZ8Ew</td>\n",
       "      <td>VG__jPnmg4Dvz7e_55iTcw</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The food has good taste but if u want a bad st...</td>\n",
       "      <td>2007-12-14 17:50:49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  k9vlSSUStwY2DcjM8Rinnw  7C8RwnXqNhj6mYxowI53sA  Of6xu3pY3eHe2yhiyz2dvg   \n",
       "1  AtNXA1mJ8BJR1OK7sM68Ug  2Y01picIp0O3uvo45l_jMQ  xyLIKm-pXy-zc29weExTZQ   \n",
       "2  HTvz23J8kC-B9ZaJ_Y9v0Q  D6dvJfPX3Pbcn5JQJZx2xA  Of6xu3pY3eHe2yhiyz2dvg   \n",
       "3  O2KoZYlcLv2QYR5C1WzQiQ  84H-Yk7MaqhCAGdk7UDjuA  8yLc33AAXB9-xn7OG4Firw   \n",
       "4  706rWMW5g-IpRT1bGD85GQ  1ENBskBHIvWPaiF-wcZ8Ew  VG__jPnmg4Dvz7e_55iTcw   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0    4.0       0      1     0   \n",
       "1    4.0       0      0     0   \n",
       "2    1.0       2      1     1   \n",
       "3    1.0       0      0     0   \n",
       "4    2.0       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Literally not a thing, anything at all,  in my...  2017-05-13 05:57:03  \n",
       "1  I've lived in the area for 5 years now. This t...  2015-08-19 16:30:22  \n",
       "2  This is probably the worst Taco Bell I've ever...  2016-03-07 02:48:02  \n",
       "3  Saturday evening, 10:30pm, closed. No explanat...  2018-07-08 02:30:44  \n",
       "4  The food has good taste but if u want a bad st...  2007-12-14 17:50:49  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tacobell and Chipotle Reviews         \n",
    "tacobell_reviews = []\n",
    "chipotle_reviews = [] \n",
    "with open('C:/Users/tsai_/Downloads/yelp_dataset/yelp_dataset/review.json', encoding = 'utf8') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        x = json.loads(line)\n",
    "        if x['business_id'] in tacobell_id: \n",
    "            tacobell_reviews.append(x)\n",
    "        if x['business_id'] in chipotle_id: \n",
    "            chipotle_reviews.append(x)        \n",
    "\n",
    "df = pd.DataFrame(tacobell_reviews)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb9a6bd",
   "metadata": {},
   "source": [
    "## Preliminary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the stars are distributed in the reviews \n",
    "# How the stars are distributed among the restaurants in the chain \n",
    "\n",
    "\n",
    "# Overall stars rating statistics\n",
    "tacobell_stars = []\n",
    "chipotle_stars = []\n",
    "for i in tacobell_reviews:\n",
    "    tacobell_stars.append(i['stars'])\n",
    "for j in chipotle_reviews:\n",
    "    chipotle_stars.append(j['stars'])\n",
    "\n",
    "tacobell_avg_rating = sum(tacobell_stars) / len(tacobell_reviews)\n",
    "chipotle_avg_rating = sum(chipotle_stars) / len(chipotle_reviews)\n",
    "\n",
    "tacobell_stars_dist = Counter(tacobell_stars)\n",
    "chipotle_stars_dist = Counter(chipotle_stars)\n",
    "\n",
    "# Stars rating distribution for each tacobell restaurant\n",
    "d1 = {}\n",
    "for i in tacobell_id:\n",
    "    d1[i] = Counter([j['stars'] for j in tacobell_reviews if j['business_id'] == i])\n",
    "\n",
    "# Average stars rating for each tacobell restaurant\n",
    "def f(i):\n",
    "    \"\"\" Returns avg rating for inputted restaurant id\"\"\"\n",
    "    c = 0\n",
    "    s = 0\n",
    "    for r in tacobell_reviews:\n",
    "        if r['business_id'] == i:\n",
    "            c += r['stars']\n",
    "            s += 1\n",
    "    return c/s \n",
    "\n",
    "tacobell_res_avg_rating = {}\n",
    "for i in tacobell_id:\n",
    "    tacobell_res_avg_rating[i] = f(i)\n",
    "\n",
    "# Stars rating distribution for each chipotle restaurant\n",
    "d2 = {}\n",
    "for i in chipotle_id:\n",
    "    d2[i] = Counter([j['stars'] for j in chipotle_reviews if j['business_id'] == i])\n",
    "\n",
    "# Average stars rating for each tacobell restuarant\n",
    "def g(i):\n",
    "    \"\"\" Returns avg rating for inputted restaurant id\"\"\"\n",
    "    c = 0\n",
    "    s = 0\n",
    "    for r in chipotle_reviews:\n",
    "        if r['business_id'] == i:\n",
    "            c += r['stars']\n",
    "            s += 1\n",
    "    return c/s \n",
    "\n",
    "chipotle_res_avg_rating = {}\n",
    "for i in chipotle_id:\n",
    "    chipotle_res_avg_rating[i] = g(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62cb86e",
   "metadata": {},
   "source": [
    "## Tacobell Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183573e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tacobell reviews per month plot\n",
    "path = 'C:/Users/tsai_/Desktop/U Wisconsin - Madison/Courses/2nd year/Fall 2021/STAT 628/Module 3'\n",
    "df_t = pd.DataFrame(tacobell_reviews)\n",
    "df_t['date'] = pd.to_datetime(df_t['date'])\n",
    "df_t = df_t.set_index('date')\n",
    "py.plot(df_t['text'].resample('M').count())\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Number of reviews')\n",
    "py.title('Number of reviews per month')\n",
    "py.savefig(path + 'tacobell reviews per month.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "\n",
    "# Distribution of Tacobell Customer ratings\n",
    "ax = sns.barplot(data=df_t, x='stars', y='stars', estimator=lambda x: len(x) / len(df_t) * 100)\n",
    "ax.set(ylabel='Percent')\n",
    "py.title('Distribution of Customer Rating')\n",
    "py.savefig(path + 'Tacobell customer ratings distribution.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "# Average Monthly Customer Rating Tacobell\n",
    "py.plot(df_t['stars'].resample('M').mean())\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Rating')\n",
    "py.title('Average Monthly Customer Rating')\n",
    "py.ylim(0, 5)\n",
    "py.savefig(path + 'tacobell average monthly customer rating.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5140cd",
   "metadata": {},
   "source": [
    "## Chipotle Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of chipotle reviews per month plot\n",
    "path = 'C:/Users/tsai_/Desktop/U Wisconsin - Madison/Courses/2nd year/Fall 2021/STAT 628/Module 3'\n",
    "df_c = pd.DataFrame(chipotle_reviews)\n",
    "df_c['date'] = pd.to_datetime(df_c['date'])\n",
    "df_c = df_c.set_index('date')\n",
    "py.plot(df_c['text'].resample('M').count())\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Number of reviews')\n",
    "py.title('Number of reviews per month')\n",
    "py.savefig(path + 'chipotle reviews per month.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "\n",
    "# Distribution of Chipotle Customer ratings\n",
    "ax = sns.barplot(data=df_c, x='stars', y='stars', estimator=lambda x: len(x) / len(df_c) * 100)\n",
    "ax.set(ylabel='Percent')\n",
    "py.title('Distribution of Customer Rating')\n",
    "py.savefig(path + 'Chipotle customer ratings distribution.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "# Average Monthly Customer Rating Chipotle\n",
    "py.plot(df_c['stars'].resample('M').mean())\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Rating')\n",
    "py.title('Average Monthly Customer Rating')\n",
    "py.ylim(0, 5)\n",
    "py.savefig(path + 'chipotle average monthly customer rating.png')\n",
    "py.show()\n",
    "py.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe893b9f",
   "metadata": {},
   "source": [
    "## Preliminary Taco Bell NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a096cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for reviews not in English \n",
    "df = df_t\n",
    "language = [detect_langs(i) for i in df.text]\n",
    "languages = [str(i[0]).split(':')[0] for i in language]\n",
    "df['language'] = languages\n",
    "\n",
    "# Remove reviews not in English\n",
    "df = df[df.language == 'en']\n",
    "\n",
    "\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "my_stop_words = set(stopwords.words('english')+list(ENGLISH_STOP_WORDS))\n",
    "\n",
    "# Nouns and adjectives from Taco Bell reviews\n",
    "nouns = []\n",
    "txt = ' '.join(df['text'])\n",
    "sentences = nltk.sent_tokenize(txt)\n",
    "for sentence in sentences:\n",
    "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS':\n",
    "            nouns.append(word)\n",
    "\n",
    "s = ''\n",
    "for i in nouns:\n",
    "    s += (i + ' ')\n",
    "\n",
    "# Noun Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s)\n",
    "py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "py.axis('off')\n",
    "py.savefig(path + 'Tacobell noun word cloud.png')\n",
    "py.show()\n",
    "py.close()\n",
    "    \n",
    "\n",
    "adj = []\n",
    "for sentence in sentences:\n",
    "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if pos == 'JJ' or pos == 'JJR' or pos == 'JJS':\n",
    "            adj.append(word)\n",
    "\n",
    "s1 = ''\n",
    "for i in adj:\n",
    "    s1 += (i + ' ')\n",
    "            \n",
    "# Adjective Word Cloud \n",
    "cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s1)\n",
    "py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "py.axis('off')\n",
    "py.savefig(path + 'Tacobell adj word cloud.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "\n",
    "# Tokenization and Bag of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "lower_full_text = full_text.lower()\n",
    "word_tokens = word_tokenize(lower_full_text)\n",
    "tokens = [] \n",
    "for word in word_tokens:\n",
    "    if word.isalpha() and word not in my_stop_words:\n",
    "        tokens.append(word)\n",
    "token_dist = FreqDist(tokens)\n",
    "dist = pd.DataFrame(token_dist.most_common(20),columns=['Word', 'Frequency'])            \n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732aba3",
   "metadata": {},
   "source": [
    "## Preliminary Chipotle NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for reviews not in English \n",
    "df = df_c\n",
    "language = [detect_langs(i) for i in df.text]\n",
    "languages = [str(i[0]).split(':')[0] for i in language]\n",
    "df['language'] = languages\n",
    "\n",
    "# Remove reviews not in English\n",
    "df = df[df.language == 'en']\n",
    "\n",
    "\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "my_stop_words = set(stopwords.words('english')+list(ENGLISH_STOP_WORDS))\n",
    "\n",
    "# Nouns and adjectives from Taco Bell reviews\n",
    "nouns = []\n",
    "txt = ' '.join(df['text'])\n",
    "sentences = nltk.sent_tokenize(txt)\n",
    "for sentence in sentences:\n",
    "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS':\n",
    "            nouns.append(word)\n",
    "\n",
    "s = ''\n",
    "for i in nouns:\n",
    "    s += (i + ' ')\n",
    "\n",
    "# Noun Word Cloud\n",
    "from wordcloud import WordCloud\n",
    "cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s)\n",
    "py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "py.axis('off')\n",
    "py.savefig(path + 'Chipotle noun word cloud.png')\n",
    "py.show()\n",
    "py.close()\n",
    "    \n",
    "\n",
    "adj = []\n",
    "for sentence in sentences:\n",
    "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if pos == 'JJ' or pos == 'JJR' or pos == 'JJS':\n",
    "            adj.append(word)\n",
    "\n",
    "s1 = ''\n",
    "for i in adj:\n",
    "    s1 += (i + ' ')\n",
    "            \n",
    "# Adjective Word Cloud \n",
    "cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s1)\n",
    "py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "py.axis('off')\n",
    "py.savefig(path + 'Chipotle adj word cloud.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "\n",
    "# Tokenization and Bag of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "lower_full_text = full_text.lower()\n",
    "word_tokens = word_tokenize(lower_full_text)\n",
    "tokens = [] \n",
    "for word in word_tokens:\n",
    "    if word.isalpha() and word not in my_stop_words:\n",
    "        tokens.append(word)\n",
    "token_dist = FreqDist(tokens)\n",
    "dist = pd.DataFrame(token_dist.most_common(20),columns=['Word', 'Frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b006540",
   "metadata": {},
   "source": [
    "## Sentiment Analysis VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d43c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = df['text'].apply(sid.polarity_scores)\n",
    "sentiment = sentiment_scores.apply(lambda x: x['compound'])\n",
    "monthly_sentiment = sentiment.resample('M').mean()\n",
    "py.plot(monthly_sentiment, color='blue')\n",
    "py.axhline(color='red')\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Sentiment')\n",
    "py.title('Average Sentiment Score over time')\n",
    "py.show()\n",
    "py.savefig(path + 'Tacobell sentiment score over time.png')\n",
    "py.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
