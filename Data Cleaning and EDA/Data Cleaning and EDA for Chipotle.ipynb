{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f723f1be",
   "metadata": {},
   "source": [
    "## STAT628 Module 3 Yelp Data \n",
    "### Brian Tsai \n",
    "#### mtsai36@wisc.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd7a864",
   "metadata": {},
   "source": [
    "### Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4a4142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from scipy import stats as st \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as py\n",
    "import seaborn as sns \n",
    "#from langdetect import detect_langs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56516750",
   "metadata": {},
   "source": [
    "### Reading Business json data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4194b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('C:/Users/tsai_/Downloads/yelp_dataset/yelp_dataset/business.json', encoding = 'utf8') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Mexican restaurants \n",
    "mex = [] \n",
    "for i in range(len(data)): \n",
    "    if data[i]['categories'] != None: \n",
    "        if 'Mex' in data[i]['categories']:\n",
    "            mex.append(data[i])\n",
    "\n",
    "# Mexican restuarants that are open            \n",
    "mex_open = []\n",
    "for i in mex: \n",
    "    if i['is_open'] == 1: \n",
    "        mex_open.append(i)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Chipotle restaurants with >= 10 reviews \n",
    "chipotle = [] \n",
    "chipotle_id = [] \n",
    "for i in mex_open:\n",
    "    if 'Chipotle Mex' in i['name'] and i['review_count'] >= 10:\n",
    "        chipotle.append(i) \n",
    "        chipotle_id.append(i['business_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1f3e9",
   "metadata": {},
   "source": [
    "## Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73584f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chipotle Reviews         \n",
    "\n",
    "chipotle_reviews = [] \n",
    "with open('C:/Users/tsai_/Downloads/yelp_dataset/yelp_dataset/review.json', encoding = 'utf8') as fl:\n",
    "    for i, line in enumerate(fl):\n",
    "        x = json.loads(line)\n",
    "        if x['business_id'] in chipotle_id: \n",
    "            chipotle_reviews.append(x)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5140cd",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/tsai_/Desktop/U Wisconsin - Madison/Courses/2nd year/Fall 2021/STAT 628/Module 3'\n",
    "df = pd.DataFrame(chipotle_reviews)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "\n",
    "# Number of chipotle reviews per month plot\n",
    "py.plot(df['text'].resample('M').count())\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Number of reviews')\n",
    "py.title('Number of reviews over time')\n",
    "py.savefig(path + 'chipotle reviews over time.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "# Distribution of Chipotle Customer ratings\n",
    "ax = sns.barplot(data=df, x='stars', y='stars', estimator=lambda x: len(x) / len(df) * 100)\n",
    "ax.set(ylabel='Percent')\n",
    "py.title('Distribution of Customer Rating')\n",
    "py.savefig(path + 'Chipotle customer ratings distribution.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "# Average Monthly Customer Rating Chipotle\n",
    "py.plot(df['stars'].resample('M').mean())\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Rating')\n",
    "py.title('Average Monthly Customer Rating')\n",
    "py.ylim(0, 5)\n",
    "py.savefig(path + 'chipotle average monthly customer rating.png')\n",
    "py.show()\n",
    "py.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4732aba3",
   "metadata": {},
   "source": [
    "## Preliminary Chipotle NLP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9966943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for reviews not in English \n",
    "language = [detect_langs(i) for i in df.text]\n",
    "languages = [str(i[0]).split(':')[0] for i in language]\n",
    "df['language'] = languages\n",
    "\n",
    "# Remove reviews not in English\n",
    "df = df[df.language == 'en']\n",
    "\n",
    "\n",
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "my_stop_words = set(stopwords.words('english')+list(ENGLISH_STOP_WORDS)+['chipotle', 'Chipotle'])\n",
    "\n",
    "# Nouns and adjectives from Taco Bell reviews\n",
    "nouns = []\n",
    "txt = ' '.join(df['text'])\n",
    "sentences = nltk.sent_tokenize(txt)\n",
    "for sentence in sentences:\n",
    "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS':\n",
    "            nouns.append(word)\n",
    "\n",
    "adj = []\n",
    "for sentence in sentences:\n",
    "    for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "        if pos == 'JJ' or pos == 'JJR' or pos == 'JJS':\n",
    "            adj.append(word)\n",
    "\n",
    "s = ''\n",
    "for i in nouns:\n",
    "    s += (i + ' ')\n",
    "\n",
    "s1 = ''\n",
    "for i in adj:\n",
    "    s1 += (i + ' ')\n",
    "    \n",
    "\n",
    "#Word Cloud\n",
    "#noun\n",
    "from wordcloud import WordCloud\n",
    "cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s)\n",
    "py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "py.axis('off')\n",
    "py.savefig(path + 'Chipotle noun word cloud.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "\n",
    "#adj\n",
    "cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s1)\n",
    "py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "py.axis('off')\n",
    "py.savefig(path + 'Chipotle adj word cloud.png')\n",
    "py.show()\n",
    "py.close()\n",
    "\n",
    "def wc(df):\n",
    "    nouns = []\n",
    "    adj = []\n",
    "    txt = ' '.join(df['text'])\n",
    "    sentences = nltk.sent_tokenize(txt)\n",
    "    for sentence in sentences:\n",
    "        for word, pos in nltk.pos_tag(nltk.word_tokenize(sentence)):\n",
    "            if pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS':\n",
    "                nouns.append(word)\n",
    "            if pos == 'JJ' or pos == 'JJR' or pos == 'JJS':\n",
    "                adj.append(word)\n",
    "    s = ''\n",
    "    for i in nouns:\n",
    "        s += (i + ' ')\n",
    "    s1 = ''\n",
    "    for i in adj:\n",
    "        s1 += (i + ' ')\n",
    "    cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s)\n",
    "    py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "    py.axis('off')\n",
    "    py.show()\n",
    "    py.close()\n",
    "    cloud_no_stopword = WordCloud(background_color='white', stopwords=my_stop_words).generate(s1)\n",
    "    py.imshow(cloud_no_stopword, interpolation='bilinear')\n",
    "    py.axis('off')\n",
    "    py.show()\n",
    "    py.close()\n",
    "    \n",
    "    \n",
    "# Tokenization and Bag of words\n",
    "# Top 20 most frequent words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "lower_full_text = full_text.lower()\n",
    "word_tokens = word_tokenize(lower_full_text)\n",
    "tokens = [] \n",
    "for word in word_tokens:\n",
    "    if word.isalpha() and word not in my_stop_words:\n",
    "        tokens.append(word)\n",
    "token_dist = FreqDist(tokens)\n",
    "dist = pd.DataFrame(token_dist.most_common(20),columns=['Word', 'Frequency'])\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b006540",
   "metadata": {},
   "source": [
    "## Sentiment Analysis VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d43c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = df['text'].apply(sid.polarity_scores)\n",
    "sentiment = sentiment_scores.apply(lambda x: x['compound'])\n",
    "monthly_sentiment = sentiment.resample('M').mean()\n",
    "py.plot(monthly_sentiment, color='blue')\n",
    "py.axhline(color='red')\n",
    "py.xlabel('Year')\n",
    "py.ylabel('Sentiment')\n",
    "py.title('Average Sentiment Score over time')\n",
    "py.show()\n",
    "py.savefig(path + 'Chipotle sentiment score over time.png')\n",
    "py.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
